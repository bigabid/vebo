# Vebo - Data Profiling & Quality Analysis

Vebo is a comprehensive data profiling system that automatically generates Python code from rules and executes quality checks against datasets.

## ğŸ—ï¸ Project Structure

```
vebo/
â”œâ”€â”€ python/                    # Python profiler implementation
â”‚   â”œâ”€â”€ vebo_profiler/        # Core profiler package
â”‚   â”‚   â””â”€â”€ core/            # Core modules (profiler, rule_engine, etc.)
â”‚   â”œâ”€â”€ requirements.txt      # Python dependencies
â”‚   â”œâ”€â”€ setup.py             # Package setup configuration  
â”‚   â””â”€â”€ server/              # FastAPI server implementation
â”œâ”€â”€ website/                  # Web interface (React/TypeScript)
â”‚   â”œâ”€â”€ src/                 # React source code
â”‚   â”œâ”€â”€ components/          # UI components
â”‚   â””â”€â”€ dist/               # Build output
â”œâ”€â”€ scripts/                  # Utility scripts
â”‚   â””â”€â”€ run_tests.py         # Test runner script
â”œâ”€â”€ rules/                    # Data quality rules and configurations  
â”‚   â”œâ”€â”€ data-quality/        # Data quality specific rules
â”‚   â”œâ”€â”€ data-types/          # Data type validation rules
â”‚   â”œâ”€â”€ cross-column/        # Cross-column relationship rules
â”‚   â””â”€â”€ table-level/         # Table-level analysis rules
â”œâ”€â”€ examples/                 # Usage examples and sample data
â”‚   â”œâ”€â”€ python/              # Python examples  
â”‚   â”œâ”€â”€ jupyter/             # Jupyter notebook examples
â”‚   â””â”€â”€ datasets/            # Sample datasets and results
â”œâ”€â”€ docs/                     # Documentation
â”‚   â”œâ”€â”€ api/                 # API documentation
â”‚   â”œâ”€â”€ guides/              # User guides
â”‚   â””â”€â”€ examples/            # Example documentation
â”œâ”€â”€ tests/                    # Test suites
â”‚   â”œâ”€â”€ unit/                # Unit tests
â”‚   â”œâ”€â”€ integration/         # Integration tests
â”‚   â”œâ”€â”€ performance/         # Performance tests
â”‚   â”œâ”€â”€ e2e/                 # End-to-end tests
â”‚   â””â”€â”€ fixtures/            # Test data and utilities
â””â”€â”€ cursor-rules-directory/   # Cursor AI rules collection
```

## ğŸš€ Quick Start

### Python Profiler

1. **Install dependencies:**
   ```bash
   cd python
   pip install -r requirements.txt
   ```

2. **Run the example:**
   ```bash
   cd examples/python
   python example_usage.py
   ```

3. **Run the tests:**
   ```bash
   python scripts/run_tests.py
   ```

### Web Interface

1. **Install dependencies:**
   ```bash
   cd website
   npm install
   ```

2. **Start development server:**
   ```bash
   npm run dev
   ```

## ğŸ“Š Features

- **Automatic Data Profiling:** Comprehensive analysis of data quality, types, and patterns
- **Rule-Based Engine:** Configurable rules for different data quality checks
- **Cross-Column Analysis:** Relationship detection between columns
- **Web Interface:** User-friendly dashboard for data exploration
- **Extensible Architecture:** Easy to add new rules and checks

## ğŸ§ª Testing

The project includes comprehensive test coverage:

- **Unit Tests:** Core component testing (`tests/unit/`)
- **Integration Tests:** Full workflow testing (`tests/integration/`)  
- **Performance Tests:** Optimization validation (`tests/performance/`)
- **End-to-End Tests:** Complete system testing (`tests/e2e/`)

Run tests with:
```bash
# All tests
python scripts/run_tests.py

# Specific test types  
python scripts/run_tests.py --type unit
python scripts/run_tests.py --type integration
python scripts/run_tests.py --type performance
```

## ğŸ“š Documentation

- [API Documentation](docs/api/)
- [User Guides](docs/guides/)
- [Examples](docs/examples/)
- [Performance Optimizations](docs/PERFORMANCE_OPTIMIZATIONS_SUMMARY.md)
- [Enhancement Summary](docs/FOCUSED_ENHANCEMENTS_SUMMARY.md)

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch  
3. Make your changes
4. Add comprehensive tests
5. Ensure all tests pass: `python scripts/run_tests.py`
6. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.